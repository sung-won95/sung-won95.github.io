[
{
	"uri": "/idea/",
	"title": "idea",
	"tags": [],
	"description": "",
	"content": "idea  뉴스 기사 크롤링을 통한 키워드 추출 및 실시간 트렌드 제공 서비스 [Trendak]     "
},
{
	"uri": "/database/",
	"title": "database",
	"tags": [],
	"description": "",
	"content": "database  postgres replication 하는방법     "
},
{
	"uri": "/devops/",
	"title": "devops",
	"tags": [],
	"description": "",
	"content": "DevOps  docker-compose에서 NFS 사용하기     Ubuntu GPU Server NVIDIA Driver 설치 방법     Docker에서 원하는 GPU선택해 컨테이너로 Project실행하기     "
},
{
	"uri": "/tech/",
	"title": "tech",
	"tags": [],
	"description": "",
	"content": "tech  Opencv를 이용하여 YOLOv4로 CCTV 영상 분석하기     "
},
{
	"uri": "/",
	"title": "슬럽의 블로그",
	"tags": [],
	"description": "",
	"content": "슬럽의 블로그 이 블로그는 제가 직접 겪은 에러사항들을 정리하고 공유하려는 목적으로 개설했습니다.\n틀린 정보가 있으면 편하게 댓글 남겨주시면 감사하겠습니다.\n idea    뉴스 기사 크롤링을 통한 키워드 추출 및 실시간 트렌드 제공 서비스 [Trendak]      database    postgres replication 하는방법      devops    docker-compose에서 NFS 사용하기     Ubuntu GPU Server NVIDIA Driver 설치 방법     Docker에서 원하는 GPU선택해 컨테이너로 Project실행하기      tech    Opencv를 이용하여 YOLOv4로 CCTV 영상 분석하기      "
},
{
	"uri": "/tags/idea/",
	"title": "idea",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/news-bot/",
	"title": "news bot",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/idea/newsbotreport/",
	"title": "뉴스 기사 크롤링을 통한 키워드 추출 및 실시간 트렌드 제공 서비스 [Trendak]",
	"tags": ["idea", "사업계획서", "news bot"],
	"description": "",
	"content": "안녕하세요 오늘은 사업계획서를 공유해보려고 합니다. 이 글은 작년 10월 모 창업 경진대회에 제출한 문서를 거의 그대로 옮겼습니다. 해당 대회에서 본선에는 들었지만 발표평가에서 떨어진 문서입니다. 사업계획서를 쓰시는 분들께 도움이 되었으면 합니다. 더불어서 피드백은 언제나 환영입니다!\n1-1. 제품의 차별성 실시간성  1분단위의 실시간 모니터링을 통해 누구보다 빠른 정보전달 가능 기존 어플리케이션들의 서비스 제공 시간폭은 유료 기준 30분 - 1시간 소요  능동적 정보제공  굳이 찾아보지 않아도 알아서 방대한 양의 정보를 정리하여 제공해줌 바쁜 현대인들에게 스스로 시의성 있는 정보와 트렌드를 전달함  제목 기반 키워드 제공  자동 요약 시스템을 통해 부담 없이 손쉽게 트렌드 파악 가능 기사 전체가 아닌 이미 요약되어 있는 제목만을 크롤링 함으로써 더 빠르고 적은 데이터로 서비스 구축 가능  접근성  별도의 앱 설치 없이 카카오톡 챗봇을 이용하여 누구나 쉽게 사용 가능  안드로이드\u0026amp;IOS 이용자 모두 이용가능   앱 알람이 아닌 다수가 사용하는 카카오톡 메시지 알람으로 다른 앱 이용보다 번거로움이 적음  확장성   내용을 집약하여 제목을 작성하는 다른 데이터에 동일한 메커니즘 적용 가능\nex) 논문, 사설, 영화 댓글 ···\n논문 \u0026gt; 특허 \u0026gt; 기사 순으로 트렌드가 정해져 미래 트랜드 예측 가능 기술\n  해외 기사, 자료들도 동일한 방식으로 크롤링\u0026amp;번역 후 제공 가능\n   1-2. 개발 동기 및 필요성 개발동기  앞서 발생한 사건들을 몰라 대화가 원활히 이뤄지지 못하는 문제가 발생하며 잘못된 정보를 가지고 말하여 정보의 왜곡 가능성이 있음 기존에도 \u0026lsquo;유튜브 오늘의 소식 요약\u0026rsquo;, \u0026lsquo;10분 뉴스 추천앱\u0026rsquo; 같은 기능이 있지만, 이동이 많아 집중이 어려운 출퇴근 시간이나, 과제 혹은 업무 도중에 빠르게 정보를 얻을 수 있는 매체가 부족함 정보의 속도가 지속적으로 빨라지고 있기에 그에 맞는 능동적 정보를 제공받을 수 있는 매체가 필요함 흥미도가 떨어지는 기사들, 이해하기 어려운 내용의 기사들 처음 뉴스, 기사를 접하려 하는 젊은이들에게 접근성이 떨어짐  필요성   뉴스가 거창하고 어렵다고 생각하는 이용자들에게 접근하기 쉬운 이미지를 심어줄 필요가 있음\n  트렌드에 민감한 젋은 세대들에게 필요한 정보를 빠르게 접할 수 있게 하여 대응력을 갖추도록 함\n  10-20 대는 뉴스, 기사 확인 보다는 동영상 시청, SNS 이용률이 높아 디지털 텍스트(인터넷 뉴스, 기사 등등) 의 이용 시간 지속적 감소\n  감소하는 디지털 텍스트 컨텐츠 이용시간의 변화에 맞게 짧고 간단하게 소식을 파악할 수 있는 장치가 필요\n  소식에 민감한 회사, 개인사업자, 주식투자자, 스포츠 애호가에게 더욱 빠른 정보 제공이 가능해짐\n   2-1. 개발방안 (시제품 제작 추진일정 등) 사용 기술 Crawling  python Scrapy NoSQL  KeyWord 추출  TextRank  ChatBot Server  Flask kakao i open builder  Infra  Cloud Docker   3-1. 자금 소요 및 조달 계획 자금 소요   Server (AWS)\n  조달계획   투자\n스타트업 투자 (카카오벤처스, KB인베스트먼트, DSC인베스트먼트, 베이스인베스트먼트, 슈미 etc\u0026hellip;)\n  구독 서비스 이익 창출\n  APP 개발 시 APP 내 광고 수익\n  3-2. 시장 분석 및 성과 창출 전략 시장분석 뉴스 시장 NEEDS  기존에 AI, 빅데이터를 접목하지 않은 서비스가 1년안에 40만 사용자를 모음  네이버 뉴스 언론사 구독자수·구독건수 2000만 달성  구독 시장 NEEDS  구독 시장은 국내는 물론 해외에서도 지속적으로 성장중  \u0026lsquo;구독경제\u0026rsquo;or\u0026rsquo;구독 경제\u0026rsquo;를 이용한 국내 기사수 추이 지역 신문사를 제외한 국내 신문사 4개년 구독 경제 기사수\n결론  구독 경제, 구독 서비스에 대한 대중의 이해도, 관심도도 높아지고 있음 현재 이용 가능한 뉴스 컨텐츠를 사용하는 이용자도 적지않음 디지털 텍스트 컨텐츠 이용 비율이 적은 10-20대 젊은 세대를 고객으로 유입 시 더 큰 시장 형성 가능  성과창출 전략 구독 서비스   1년안에 카카오톡 친구추가 50만, APP스토어(IOS)\u0026amp;PLAY스토어(ANDROID) 다운로드 10만 이상이 목표\n  다운로드 사용자 중 10% 구독 서비스 유치 목표\n구독자 이용 가능 컨텐츠  광고제거 맞춤 키워드 추가 제공 검색어 비율 설정가능 축적된 데이터 접근 가능 ex) 연령별 관심사, 키워드 채택 비율, 증가율 등  구독경제관련 뉴스\n온라인 구독 서비스 이용 행태 분석\n   출처 박성원 : parksw1992@naver.com\n이재상 : imjsl22@gmail.com\n"
},
{
	"uri": "/tags/%EC%82%AC%EC%97%85%EA%B3%84%ED%9A%8D%EC%84%9C/",
	"title": "사업계획서",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/docker/",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/docker-compose/",
	"title": "docker-compose",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/docker-volumn-nfs/",
	"title": "docker-compose에서 NFS 사용하기",
	"tags": ["nfs", "docker", "docker-compose", "volume"],
	"description": "",
	"content": "Docker-compose Setting version: \u0026#39;3.1\u0026#39; volumes: nfs-data: #nfs volume 이름 지정  driver: local  driver_opts: type: nfs  #nfs 서비스로 지정  device: \u0026#34;:/your/nfs/path\u0026#34; #nfs mount 경로 o: \u0026#34;addr=192.168.2.27,nolock,soft,rw\u0026#34; #nfs서버 세팅 services: AI-blur: image: blur deploy: resources: limits: cpus: \u0026#39;24\u0026#39; memory: 128G build: context: . dockerfile: blur/Dockerfile environment: - NVIDIA_VISIBLE_DEVICES=2,3,4,5  #GPU 설정 env volumes: - nfs-blur:/root/workspace/nfs-data  # [volume명]:[컨테이너 내부 마운트 위치] stdin_open: true tty: true docker-compose에서도 위와같이 nfs를 사용 할 수 있습니다!\n추가적으로 궁금하신건 아래 링크 중 volume 부분 참고하시면 됩니다\nDocker-Compose-공식문서\n"
},
{
	"uri": "/tags/nfs/",
	"title": "nfs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia/",
	"title": "nvidia",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia-driver/",
	"title": "nvidia-driver",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia-smi/",
	"title": "nvidia-smi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/opencv/",
	"title": "opencv",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tech/rtsp-opencv-yolov4/",
	"title": "Opencv를 이용하여 YOLOv4로 CCTV 영상 분석하기",
	"tags": ["python", "tensorflow", "rtsp", "yolo", "opencv"],
	"description": "",
	"content": "프롤로그 안녕하세요 오늘은 OpenCV를 사용하여 CCTV video stream(RTSP)에 YOLO를 돌린 프로젝트 후기를 남겨보려고 합니다. 이 프로젝트는 실시간으로 object detecting 하는 것을 최우선 목표로 진행했습니다. 2K CCTV에서 RTSP 서버를 열어주고 딥러닝(YOLO v4)을 통해 object detecting을 진행 한 뒤 모니터링 서버에서 보여줄때까지 지연시간이 2초 이하로 진행해야 했습니다.\n환경 \u0026amp; 목표 w\n CCTV : 2K RTSP Stream, 16EA Network : 10G GPU : Tesla T4, 8EA AI Model : YOLO v4, 5개 object 구분 목표 : 모니터링 서버에서 2초 이내 detecting object 확인  설계도 RTSP → YOLO v4(분석) | Tesla T4 이용 → View\np.s. YOLO v4(학습 class 5개, 총 용량 268M)모델 2개를 Tesla T4 16GB를 사용해 인퍼런스를 진행하면 10FPS 방어가 가능했습니다.\nDocker Setting TensorFlow GPU버전을 사용해야 하기에 tensorflow 공식 이미지중 gpu 태그가 붙은 이미지를 사용했습니다. 또한 docker 내부에서 OpenCV도 사용해야 했기에 ffmpeg을 설치해줬습니다.\ndocker-compose에서 GPU세팅 및 OpenCV 사용 세팅은 (여기)를 참고해 주세요\nDockerfile FROMtensorflow/tensorflow:2.3.0-gpuRUN apt-get updateRUN apt-get install ffmpeg libsm6 libxext6 -yWORKDIR/srcENV PYTHONUNBUFFERED=0 COPY python/requirements.txt ./RUN pip3 install --no-cache-dir -r requirements.txt COPY . /modulerequirements.txt amqp==5.0.1 billiard==3.6.3.0 celery==5.0.0 click==7.1.2 click-didyoumean==0.0.3 click-repl==0.1.6 kombu==5.0.2 prompt-toolkit==3.0.7 pytz==2020.1 vine==5.0.0 wcwidth==0.2.5 opencv-python lxml tqdm absl-py matplotlib easydict pillow docker-compose version: \u0026#39;3.1\u0026#39; services: AirForcePython1: image: tensor_ai deploy: resources: limits: cpus: \u0026#39;1\u0026#39; build: context: . dockerfile: python/Dockerfile volumes: - ../src:/src environment: - VideoPath=rtsp://admin:qazwsx123!@192.168.0.1:554/RTSPSTREAM - CameraId=camera1 - DestIp=192.168.0.1 - DISPLAY=unix$DISPLAY - NVIDIA_VISIBLE_DEVICES=0 - model=yolov4_airforce command: python detectvideo.py stdin_open: true tty: true 삽질의 기록 GPU를 어떻게 나누지\u0026hellip;. 처음 시작하면서 부터 난관에 봉착했습니다. 일단 TensorFlow를 실행해서 YOLO를 돌린것까진 좋았는데\u0026hellip; 프레임당 100ms 이하로 나오는것도 좋았는데 YOLO를 실행하기만 하면 GPU RAM을 모두 다 차지해버립니다. OTL\u0026hellip; 열심히 구글링 해본 결과 config.gpu_options.allow_growth 옵션을 끄지 않으면 TensorFlow가 남은 GPU RAM을 모두 선점해버리는 현상이 있었습니다. 해결 방법으로는 옵션을 False로 바꾸고 초기 RAM을 얼만큼 차지할지 config.gpu_options.per_process_gpu_memory_fraction 옵션에 넣어주면 됩니다!!! 저는 테스트 결과 stream 3개까지도 아슬아슬하게 10 FPS 방어가 됐는데 GPU가 모자라는게 아니니 GPU 1개당 2개 Stream을 할당해줬습니다.\np.s. 각 GPU에 할당하는건 docker-compose 에서 세팅해줬습니다. NVIDIA_VISIBLE_DEVICES 옵션을 잘 세팅하시면 됩니다 ㅎㅅㅎ\nconfig = ConfigProto() config.gpu_options.allow_growth = False config.gpu_options.per_process_gpu_memory_fraction = 0.4 session = InteractiveSession(config=config) Docker가 이유없이 계속 죽는다\u0026hellip;. try catch로 감싸진게 전혀 없는데 log를 아무리 뒤져도 에러코드가 나오지 않고 죽는 현상이 있었습니다. 정말 docker stop 명령어를 쓴 듯 갑자기 docker가 죽어버렸습니다. 이것도 반나절동안 삽질한 결과 OOM(Out Of Memory)라는 결론을 얻었습니다. RTSP Stream에서 가지고 오는 속도에 비해 object detecting 속도가 느려 메모리에 계속 쌓였던게 원인이였습니다. 이 문제를 해결하기 위해 아래처럼 queue를 사용했습니다. queue size를 3으로 해놓으면 버퍼가 체감이 되었으며 그렇다고 사이즈를 1로 해놓으면 프레임 대기시간이 생기는건지 2보다 느린 관계로 queue size는 2로 설정했습니다\nimport queue q = queue.Queue(2) def Receive(): video_path = os.environ[\u0026#34;VideoPath\u0026#34;] vid = cv2.VideoCapture(video_path) while True: return_value, frame = vid.read() if return_value: q.put(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) def main(_argv): p1 = threading.Thread(target=Receive) p1.start() while True: try: if q.empty() != True: frame = q.get() # next Code RTSP Stream 재부팅시 자동 연결이 안된다\u0026hellip;. 위와 비슷하지만 docker가 죽진 않았으나 더이상 detecting log가 쌓이지 않는 현상이 있었습니다. 바로 RTSP Stream이 죽어도 receive 함수가 죽지 않았던 것입니다. 단순하게 생각해서 RTSP Stream이 재부팅 되어도 URL이 바뀌지도 않고 기존에 Stream을 계속 read하려고 하면 재부팅 된 뒤 read가 될 줄 알았던 제 어리석은 생각때문이였습니다. vid.read()에서 왜 true, false를 반환하겠니\u0026hellip;\u0026hellip; 여튼 그래서 vid.read가 false를 반환할 때 제 쓰레드를 죽인 뒤 다시 쓰레드를 생성해 새로운 stream을 받아오는걸로 코딩을 했습니다. 쓰레드를 생성할 때 setDaemon(True) 설정 안하면 thread가 정상적으로 죽지 않아서 ram 누수가 발생합니다. 그러니 꼭 setDaemon(True) 설정을 해주시고 맨위에 객체 만들었다고 새로운 객체를 만들지 않고 다시 start 함수만 사용하면 에러가 발생합니다. 어차피 기존 쓰레드는 반납되었으니 새로운 쓰레드를 만들어 사용하는게 좋습니다.\ndef Receive(): print(\u0026#34;start Reveive\u0026#34;) video_path = os.environ[\u0026#34;VideoPath\u0026#34;] print(\u0026#34;Video from: \u0026#34;, video_path ) vid = cv2.VideoCapture(video_path) while True: return_value, frame = vid.read() if return_value: q.put(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) else: break def main(_argv): p1 = threading.Thread(target=Receive) p1.setDaemon(True) p1.start() while True: if q.empty() != True: frame = q.get() # next Code elif not p1.isAlive(): time.sleep(5) p1 = threading.Thread(target=Receive) p1.setDaemon(True) p1.start() 이렇게 RTSP Stream으로부터 원하는 만큼의 GPU를 사용해 딥러닝을 돌려 확인하는 것 까지 내용을 마쳤습니다. 추후에 이슈사항이 있으면 이 페이지에 추가하겠습니다.\n모든 서버에서 실시간성이 보장되지 않는다. 2020-12-28 여러개의 서버에서 동일한 실시간성이 보장되어야 하는 프로젝트였으나 사양이 더 좋은 서버에서 실시간성이 보장 안되는 이슈가 있었습니다. 이 이슈는 아래 pipe를 생성해서 사용하는것으로 해결했습니다.\n제 생각이지만 cv2.videoCapture를 사용하면 ffmpeg에 버퍼를 먼저 채운 뒤 프레임을 읽어와 제공을 해주는 것 같습니다. 또한 cv2 자체에서도 특정 조건을 만족했을 때 딜레이가 발생하는데 정확한 원인을 모르겠습니다. 혹시 아시는분이 계시다면 댓글 남겨주세요\nimport cv2 import subprocess as sp import numpy command = [\u0026#39;ffmpeg\u0026#39;, \u0026#39;-i\u0026#39;, \u0026#39;rtsp://78.10.34.92/axis-media/media.amp\u0026#39;, \u0026#39;-f\u0026#39;, \u0026#39;image2pipe\u0026#39;, \u0026#39;-pix_fmt\u0026#39;, \u0026#39;bgr24\u0026#39;, \u0026#39;-vcodec\u0026#39;, \u0026#39;rawvideo\u0026#39;, \u0026#39;-\u0026#39;] pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=1280 * 800 * 3) while pipe.poll() is None: if cv2.waitKey(1) \u0026amp; 0xFF == ord(\u0026#39;q\u0026#39;): break raw_image = pipe.stdout.read(1280 * 800 * 3) image1 = numpy.frombuffer(raw_image, dtype=\u0026#39;uint8\u0026#39;) image2 = image1.reshape((800, 1280, 3)) cv2.imshow(\u0026#39;Video\u0026#39;, image2) pipe.stdout.flush() pipe.terminate() cv2.destroyAllWindows() 궁금한점이나 피드백은 환영합니다. 감사합니다.\n"
},
{
	"uri": "/tags/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/rtsp/",
	"title": "rtsp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/tensorflow/",
	"title": "tensorflow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/nvidia-driver-install/",
	"title": "Ubuntu GPU Server NVIDIA Driver 설치 방법",
	"tags": ["nvidia", "nvidia-smi", "nvidia-driver"],
	"description": "",
	"content": "nvidia driver 설치 전 사전 세팅  OS : ubuntu 18.04  먼저 Ubuntu는 gcc와 make가 설치되어있지 않습니다. 그렇기에 apt-get으로 gcc와 make를 설치해 줍니다.\napt-get install -y gcc make 설치가 완료되었으면 nouveau를 비활성화 해줍니다. nouveau는 기본 onboard 그래픽 드라이버로 이 모듈이 활성화 되어있으면 GPU를 선점해 nvidia-driver가 정상적으로 설치되지가 않습니다. 이 모듈을 비활성화 하는 방법으로는 다양한 방법이 있는데 저는 아래와 같이 blacklist로 지정해서 reboot 하는 방식으로 했습니다. 아시는 방법이 있다면 본인이 편하신 방법대로 모듈을 비활성화 해주시면 됩니다.\n#nouveau blacklist 설정 echo \u0026#34;blacklist nouveau\u0026#34; \u0026gt;\u0026gt; /etc/modprobe.d/blacklist.conf echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf update-initramfs -u # options 에서 설정한 값 적용 코드 reboot now # blacklist 적용용 reboot  비활성화가 정상적으로 되었는지는 아래 명령어를 입력했을때 아무것도 출력되지 않으면 됩니다!\nlsmod | grep nouveau nvidia driver 검색 후 설치  nvidia.com 에 접속 제품 에 맞는 드라이버 선택 후 검색다운로드 하기(wget 가능)  wget [http://us.download.nvidia.com/XFree86/Linux-x86_64/440.44/NVIDIA-Linux-x86_64-440.44.run](http://us.download.nvidia.com/XFree86/Linux-x86_64/440.44/NVIDIA-Linux-x86_64-440.44.run) chmod +x NVIDIA-Linux-x86_64-440.44.run ./NVIDIA-Linux-x86_64-440.44.run 설치 후 nvidia-smi 로 설치되었는지 확인하시면 됩니다!\n"
},
{
	"uri": "/tags/volume/",
	"title": "volume",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/yolo/",
	"title": "yolo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/docker-gpu-1/",
	"title": "Docker에서 원하는 GPU선택해 컨테이너로 Project실행하기",
	"tags": ["GPU", "docker", "docker-compose"],
	"description": "",
	"content": "기본 서버 설정 OS : Ubuntu 18.04\nInstall Package: Nvidia-driver \u0026amp; nvidia-docker 설치\nDocker GPU 사용 세팅 docker 명령어를 사용하면 기본적으로 /usr/bin 경로에 있는 docker 파일이 실행됩니다. 하지만 우리의 목적은 GPU를 사용하는 것 이기 때문에 docker 명령어가 아닌 nvidia-docker를 사용해야 합니다. docker 와 nvidia-docker를 번갈아가면서 사용하게 된다면 헷갈리기도 하고 kubernetes, docker-compose에서는 기본적으로 docker파일을 실행하도록 설정되어 있기 때문에 default runtime을 nvidia-docker로 사용 할 수 있도록 세팅해 줘야 합니다.\n/etc/docker/daemon.json파일 중 첫번째줄에 \u0026ldquo;default-runtime\u0026rdquo;: \u0026ldquo;nvidia\u0026quot;부분을 추가해 주면 세팅은 완료 됩니다.\n/etc/docker/daemon.json { \u0026#34;default-runtime\u0026#34;: \u0026#34;nvidia\u0026#34;, \u0026#34;runtimes\u0026#34;: { \u0026#34;nvidia\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/usr/bin/nvidia-container-runtime\u0026#34;, \u0026#34;runtimeArgs\u0026#34;: [] } } } 이 세팅을 완료했으면 이제 nvidia-docker 명령어와 docker 명령어 중 어떤것을 사용하든 nvidia-docker가 실행됩니다. 이제 어떤 GPU를 사용 할 것인지 우리가 사용할 수 있는 GPU가 뭐가 있는지 확인한 뒤 선택해서 사용하면 됩니다.\nnvidia-smi 확인을 해보니 0번 GPU는 2개의 프로세스가 각 7091Mib씩 차지하며 어떠한 작업을 돌리고 있는것이 보이네요!\n그럼 작업에 문제 주지 않게 1번 GPU 사용하는걸로 생각하면서 Project를 만들어 보겠습니다.\nProject Tree 저는 늘 프로젝트 시작시에 docker, src 폴더를 만들어주고 시작합니다.\n docker : docker-compose.yml파일이 있고 docker image build부터 environment 까지 모두 관리 하는 폴더입니다. 개발환경 세팅하기 편하며 추후에 CI/CD를 세팅할때도 참고하기 편합니다.\np.s. docker-compose에서 nfs도 사용 할 수 있습니다! 만약 nfs를 사용하고 싶으시면(여기) 참고하시면 됩니다! src : 실제 실행되는 소스코드를 저장합니다. docker를 실행해 volume mount를 할때는 data, src 등 직관적인 폴더를 추가만 하면 되고 관리도 매우매우 편해졌습니다.  전체 Project Tree docker Tree docker-compose.yml 세팅 version: \u0026#39;3.1\u0026#39; services: Python1: #docker파일 이름 image: tensor_ai  #docker image 이름 deploy: #docker container 사양 설정 resources: limits: cpus: \u0026#39;1\u0026#39; build: #docker image build 방법  context: .  #build root 경로 이 위치를 dockerfile이 있는 폴더로 지정 한 다음 파일명만 써도 됨  dockerfile: python/Dockerfile  # Dockerfile 이름 지정 | Dockerfile이면 지정 안해도 되지만 혹시나 몰라서... volumes: - ../src:/src #컨테이너와 실제 서버 마운트 | 실제 서버 경로 : container 경로 environment: #컨테이너 안에서 사용할 환경변수  - NVIDIA_VISIBLE_DEVICES=1  #어떤 GPU를 사용할건지 입력 | 다중사용을 원하면 0,1 과 같이 \u0026#34;,\u0026#34;로 구분해서 넣으면 됨 - VideoPath=rtsp://admin:admin!@127.0.0.1 # 여기부터 아래는 실제 소스에서 사용할 env - CameraId=camera1  # Python에서 os.environ[\u0026#34;CameraId\u0026#34;] 로 사용  - DISPLAY=unix$DISPLAY  # openCV를 container 안에서 사용하려면 설정을 넣어 줘야함 - model=tensor_model command: python detectvideo.py  # 컨테이너가 올라갈때 입력할 명령어 stdin_open: true tty: true 위와 같이 docker-compose.yml 파일을 만들고 나서 docker compose up 명령어를 치면 docker container 안에서 GPU를 사용할 수 있습니다!\n1번 GPU에 잘 올라 가네요!\n혹시나 잘못된 정보가 있으면 피드백 해 주세요!\n감사합니다\n"
},
{
	"uri": "/tags/gpu/",
	"title": "GPU",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/postgres/",
	"title": "postgres",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/database/postgres-replication-setting/",
	"title": "postgres replication 하는방법",
	"tags": ["replication", "postgres"],
	"description": "",
	"content": "master 서버와 slave 서버에 각각 설정하는 방법이 다릅니다\nMASTER 설정   user 생성\n# psql을 Postgres 유저로 접속 후 유저 생성 sudo -u postgres psql CREATE ROLE replication WITH REPLICATION PASSWORD \u0026#39;password\u0026#39; LOGIN;   /etc/postgresql/9.5/main/postgresql.conf 파일 수정\nwal_level = hot_standby max_wal_senders = 2 max_replication_slots = 2   /etc/postgresql/9.5/main/hba.conf 파일 수정\n아래 문구 추가\nhost all all 192.168.0.138/24 trust host replication replication 192.168.0.138/24 md5 host all all ::1/128 trust   postgresql 재시작\n  STANDBY SERVER 세팅   /etc/postgresql/9.5/main/pg_hba.conf 파일 수정 아래문구 추가\nhost all all 192.168.0.0/24 trust   postgres 유저 추가\n# psql을 Postgres 유저로 접속 후 유저 생성 sudo -u postgres psql CREATE ROLE replication WITH REPLICATION PASSWORD \u0026#39;password\u0026#39; LOGIN;   master server backup 진행\n# 백업 진행하기 전 postgresql 종료 systemctl stop postgresql # 백업은 꼭 postgres 유저로 진행해야 됨 (중요) su postgres # /var/lib/postgresql/9.5/main 아래의 데이터는 데이터 베이스가 동작하는 main 디렉토리 # 하위 데이터가 없어야 백업이 정상적으로 실행됨 rm -rf /var/lib/postgresql/9.5/main/* pg_basebackup -h 192.168.0.123 -D /var/lib/postgresql/9.5/main/ -U replication -P -v -X stream   /var/lib/postgresql/9.5/main/recovery 파일 생성\nstandby_mode=\u0026#39;on\u0026#39; primary_conninfo=\u0026#39;host=192.168.0.123 port=5432 user=replication password=password\u0026#39; primary_slot_name=\u0026#39;repl_slot_01\u0026#39; trigger_file=\u0026#39;/var/lib/postgresql/9.5/main/failover_trigger\u0026#39;   postgresql 실행\nsystemctl start postgresql   replication 실행 확인   master 서버에서의 확인\nselect * from pg_stat_replication; 아래처럼 1 row 가 출력되면 1개의 replication이 돌고 있는 것   slave 에서의 확인\n/var/log/postgresql/postgresql-9.5-main.log 로그에서 아래와 같이 recovery 로그가 있으면 성공\n  master / slave 모두 확인\nps -ef | grep post 를 입력했을때 아래와 같이 recovering 이라는 프로세스가 돌고있으면 성공!\n  혹시 틀린부분 있으면 피드백 부탁드립니다!\n"
},
{
	"uri": "/tags/replication/",
	"title": "replication",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]