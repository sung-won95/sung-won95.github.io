[
{
	"uri": "/database/",
	"title": "database",
	"tags": [],
	"description": "",
	"content": "database  postgres replication 하는방법     "
},
{
	"uri": "/devops/",
	"title": "devops",
	"tags": [],
	"description": "",
	"content": "DevOps  docker-compose에서 NFS 사용하기     Ubuntu GPU Server NVIDIA Driver 설치 방법     Docker에서 원하는 GPU선택해 컨테이너로 Project실행하기     "
},
{
	"uri": "/tech/",
	"title": "tech",
	"tags": [],
	"description": "",
	"content": "tech  Opencv를 이용하여 YOLOv4로 CCTV 영상 분석하기     "
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/docker/",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/docker-compose/",
	"title": "docker-compose",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/docker-volumn-nfs/",
	"title": "docker-compose에서 NFS 사용하기",
	"tags": ["nfs", "docker", "docker-compose", "volume"],
	"description": "",
	"content": "Docker-compose Setting version: \u0026#39;3.1\u0026#39; volumes: nfs-data: #nfs volume 이름 지정  driver: local  driver_opts: type: nfs  #nfs 서비스로 지정  device: \u0026#34;:/your/nfs/path\u0026#34; #nfs mount 경로 o: \u0026#34;addr=192.168.2.27,nolock,soft,rw\u0026#34; #nfs서버 세팅 services: AI-blur: image: blur deploy: resources: limits: cpus: \u0026#39;24\u0026#39; memory: 128G build: context: . dockerfile: blur/Dockerfile environment: - NVIDIA_VISIBLE_DEVICES=2,3,4,5  #GPU 설정 env volumes: - nfs-blur:/root/workspace/nfs-data  # [volume명]:[컨테이너 내부 마운트 위치] stdin_open: true tty: true docker-compose에서도 위와같이 nfs를 사용 할 수 있습니다!\n추가적으로 궁금하신건 아래 링크 중 volume 부분 참고하시면 됩니다\nDocker-Compose-공식문서\n"
},
{
	"uri": "/tags/nfs/",
	"title": "nfs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia/",
	"title": "nvidia",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia-driver/",
	"title": "nvidia-driver",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/nvidia-smi/",
	"title": "nvidia-smi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/opencv/",
	"title": "opencv",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tech/rtsp-opencv-yolov4/",
	"title": "Opencv를 이용하여 YOLOv4로 CCTV 영상 분석하기",
	"tags": ["python", "tensorflow", "rtsp", "yolo", "opencv"],
	"description": "",
	"content": "프롤로그 안녕하세요 오늘은 OpenCV를 사용하여 CCTV video stream(RTSP)에 YOLO를 돌린 프로젝트 후기를 남겨보려고 합니다. 이 프로젝트는 실시간으로 object detecting 하는 것을 최우선 목표로 진행했습니다. 2K CCTV에서 RTSP 서버를 열어주고 딥러닝(YOLO v4)을 통해 object detecting을 진행 한 뒤 모니터링 서버에서 보여줄때까지 지연시간이 2초 이하로 진행해야 했습니다.\n환경 \u0026amp; 목표  CCTV : 2K RTSP Stream, 16EA Network : 10G GPU : Tesla T4, 8EA AI Model : YOLO v4, 5개 object 구분 목표 : 모니터링 서버에서 2초 이내 detecting object 확인  설계도 RTSP → YOLO v4(분석) | Tesla T4 이용 → View\np.s. YOLO v4(학습 class 5개, 총 용량 268M)모델 2개를 Tesla T4 16GB를 사용해 인퍼런스를 진행하면 10FPS 방어가 가능했습니다.\nDocker Setting TensorFlow GPU버전을 사용해야 하기에 tensorflow 공식 이미지중 gpu 태그가 붙은 이미지를 사용했습니다. 또한 docker 내부에서 OpenCV도 사용해야 했기에 ffmpeg을 설치해줬습니다.\ndocker-compose에서 GPU세팅 및 OpenCV 사용 세팅은 (여기)를 참고해 주세요\nDockerfile FROMtensorflow/tensorflow:2.3.0-gpuRUN apt-get updateRUN apt-get install ffmpeg libsm6 libxext6 -yWORKDIR/srcENV PYTHONUNBUFFERED=0 COPY python/requirements.txt ./RUN pip3 install --no-cache-dir -r requirements.txt COPY . /modulerequirements.txt amqp==5.0.1 billiard==3.6.3.0 celery==5.0.0 click==7.1.2 click-didyoumean==0.0.3 click-repl==0.1.6 kombu==5.0.2 prompt-toolkit==3.0.7 pytz==2020.1 vine==5.0.0 wcwidth==0.2.5 opencv-python lxml tqdm absl-py matplotlib easydict pillow docker-compose version: \u0026#39;3.1\u0026#39; services: AirForcePython1: image: tensor_ai deploy: resources: limits: cpus: \u0026#39;1\u0026#39; build: context: . dockerfile: python/Dockerfile volumes: - ../src:/src environment: - VideoPath=rtsp://admin:qazwsx123!@192.168.0.1:554/RTSPSTREAM - CameraId=camera1 - DestIp=192.168.0.1 - DISPLAY=unix$DISPLAY - NVIDIA_VISIBLE_DEVICES=0 - model=yolov4_airforce command: python detectvideo.py stdin_open: true tty: true 삽질의 기록 GPU를 어떻게 나누지\u0026hellip;. 처음 시작하면서 부터 난관에 봉착했습니다. 일단 TensorFlow를 실행해서 YOLO를 돌린것까진 좋았는데\u0026hellip; 프레임당 100ms 이하로 나오는것도 좋았는데 YOLO를 실행하기만 하면 GPU RAM을 모두 다 차지해버립니다. OTL\u0026hellip; 열심히 구글링 해본 결과 config.gpu_options.allow_growth 옵션을 끄지 않으면 TensorFlow가 남은 GPU RAM을 모두 선점해버리는 현상이 있었습니다. 해결 방법으로는 옵션을 False로 바꾸고 초기 RAM을 얼만큼 차지할지 config.gpu_options.per_process_gpu_memory_fraction 옵션에 넣어주면 됩니다!!! 저는 테스트 결과 stream 3개까지도 아슬아슬하게 10 FPS 방어가 됐는데 GPU가 모자라는게 아니니 GPU 1개당 2개 Stream을 할당해줬습니다.\np.s. 각 GPU에 할당하는건 docker-compose 에서 세팅해줬습니다. NVIDIA_VISIBLE_DEVICES 옵션을 잘 세팅하시면 됩니다 ㅎㅅㅎ\nconfig = ConfigProto() config.gpu_options.allow_growth = False config.gpu_options.per_process_gpu_memory_fraction = 0.4 session = InteractiveSession(config=config) Docker가 이유없이 계속 죽는다\u0026hellip;. try catch로 감싸진게 전혀 없는데 log를 아무리 뒤져도 에러코드가 나오지 않고 죽는 현상이 있었습니다. 정말 docker stop 명령어를 쓴 듯 갑자기 docker가 죽어버렸습니다. 이것도 반나절동안 삽질한 결과 OOM(Out Of Memory)라는 결론을 얻었습니다. RTSP Stream에서 가지고 오는 속도에 비해 object detecting 속도가 느려 메모리에 계속 쌓였던게 원인이였습니다. 이 문제를 해결하기 위해 아래처럼 queue를 사용했습니다. queue size를 3으로 해놓으면 버퍼가 체감이 되었으며 그렇다고 사이즈를 1로 해놓으면 프레임 대기시간이 생기는건지 2보다 느린 관계로 queue size는 2로 설정했습니다\nimport queue q = queue.Queue(2) def Receive(): video_path = os.environ[\u0026#34;VideoPath\u0026#34;] vid = cv2.VideoCapture(video_path) while True: return_value, frame = vid.read() if return_value: q.put(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) def main(_argv): p1 = threading.Thread(target=Receive) p1.start() while True: try: if q.empty() != True: frame = q.get() # next Code RTSP Stream 재부팅시 자동 연결이 안된다\u0026hellip;. 드디어 마지막 에러사항입니다! 위와 비슷하지만 docker가 죽진 않았으나 더이상 detecting log가 쌓이지 않는 현상이 있었습니다. 바로 RTSP Stream이 죽어도 receive 함수가 죽지 않았던 것입니다. 단순하게 생각해서 RTSP Stream이 재부팅 되어도 URL이 바뀌지도 않고 기존에 Stream을 계속 read하려고 하면 재부팅 된 뒤 read가 될 줄 알았던 제 어리석은 생각때문이였습니다. vid.read()에서 왜 true, false를 반환하겠니\u0026hellip;\u0026hellip; 여튼 그래서 vid.read가 false를 반환할 때 제 쓰레드를 죽인 뒤 다시 쓰레드를 생성해 새로운 stream을 받아오는걸로 코딩을 했습니다. 쓰레드를 생성할 때 setDaemon(True) 설정 안하면 thread가 정상적으로 죽지 않아서 ram 누수가 발생합니다. 그러니 꼭 setDaemon(True) 설정을 해주시고 맨위에 객체 만들었다고 새로운 객체를 만들지 않고 다시 start 함수만 사용하면 에러가 발생합니다. 어차피 기존 쓰레드는 반납되었으니 새로운 쓰레드를 만들어 사용하는게 좋습니다.\ndef Receive(): print(\u0026#34;start Reveive\u0026#34;) video_path = os.environ[\u0026#34;VideoPath\u0026#34;] print(\u0026#34;Video from: \u0026#34;, video_path ) vid = cv2.VideoCapture(video_path) while True: return_value, frame = vid.read() if return_value: q.put(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) else: break def main(_argv): p1 = threading.Thread(target=Receive) p1.setDaemon(True) p1.start() while True: if q.empty() != True: frame = q.get() # next Code elif not p1.isAlive(): time.sleep(5) p1 = threading.Thread(target=Receive) p1.setDaemon(True) p1.start() 이렇게 RTSP Stream으로부터 원하는 만큼의 GPU를 사용해 딥러닝을 돌려 확인하는 것 까지 내용을 마쳤습니다. 추후에 이슈사항이 있으면 이 페이지에 추가하겠습니다.\n궁금한점이나 피드백은 환영합니다. 감사합니다.\n"
},
{
	"uri": "/tags/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/rtsp/",
	"title": "rtsp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/tensorflow/",
	"title": "tensorflow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/nvidia-driver-install/",
	"title": "Ubuntu GPU Server NVIDIA Driver 설치 방법",
	"tags": ["nvidia", "nvidia-smi", "nvidia-driver"],
	"description": "",
	"content": "nvidia driver 설치 전 사전 세팅  OS : ubuntu 18.04  apt-get install -y gcc make #nouveau blacklist 설정 echo \u0026#34;blacklist nouveau\u0026#34; \u0026gt;\u0026gt; /etc/modprobe.d/blacklist.conf echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf update-initramfs -u # options 에서 설정한 값 적용 코드 reboot now # blacklist 적용용 reboot  nvidia driver 검색 후 설치  nvidia.com 에 접속 제품 에 맞는 드라이버 선택 후 검색다운로드 하기(wget 가능)  wget [http://us.download.nvidia.com/XFree86/Linux-x86_64/440.44/NVIDIA-Linux-x86_64-440.44.run](http://us.download.nvidia.com/XFree86/Linux-x86_64/440.44/NVIDIA-Linux-x86_64-440.44.run) chmod +x NVIDIA-Linux-x86_64-440.44.run ./NVIDIA-Linux-x86_64-440.44.run 설치 후 nvidia-smi 로 설치되었는지 확인하시면 됩니다!\n"
},
{
	"uri": "/tags/volume/",
	"title": "volume",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/yolo/",
	"title": "yolo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/docker-gpu-1/",
	"title": "Docker에서 원하는 GPU선택해 컨테이너로 Project실행하기",
	"tags": ["GPU", "docker", "docker-compose"],
	"description": "",
	"content": "기본 서버 설정 OS : Ubuntu 18.04\nInstall Package: Nvidia-driver \u0026amp; nvidia-docker 설치\nDocker GPU 사용 세팅 docker 명령어를 사용하면 기본적으로 /usr/bin 경로에 있는 docker 파일이 실행됩니다. 하지만 우리의 목적은 GPU를 사용하는 것 이기 때문에 docker 명령어가 아닌 nvidia-docker를 사용해야 합니다. docker 와 nvidia-docker를 번갈아가면서 사용하게 된다면 헷갈리기도 하고 kubernetes, docker-compose에서는 기본적으로 docker파일을 실행하도록 설정되어 있기 때문에 default runtime을 nvidia-docker로 사용 할 수 있도록 세팅해 줘야 합니다.\n/etc/docker/daemon.json파일 중 첫번째줄에 \u0026ldquo;default-runtime\u0026rdquo;: \u0026ldquo;nvidia\u0026quot;부분을 추가해 주면 세팅은 완료 됩니다.\n/etc/docker/daemon.json { \u0026#34;default-runtime\u0026#34;: \u0026#34;nvidia\u0026#34;, \u0026#34;runtimes\u0026#34;: { \u0026#34;nvidia\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/usr/bin/nvidia-container-runtime\u0026#34;, \u0026#34;runtimeArgs\u0026#34;: [] } } } 이 세팅을 완료했으면 이제 nvidia-docker 명령어와 docker 명령어 중 어떤것을 사용하든 nvidia-docker가 실행됩니다. 이제 어떤 GPU를 사용 할 것인지 우리가 사용할 수 있는 GPU가 뭐가 있는지 확인한 뒤 선택해서 사용하면 됩니다.\nnvidia-smi 확인을 해보니 0번 GPU는 2개의 프로세스가 각 7091Mib씩 차지하며 어떠한 작업을 돌리고 있는것이 보이네요!\n그럼 작업에 문제 주지 않게 1번 GPU 사용하는걸로 생각하면서 Project를 만들어 보겠습니다.\nProject Tree 저는 늘 프로젝트 시작시에 docker, src 폴더를 만들어주고 시작합니다.\n docker : docker-compose.yml파일이 있고 docker image build부터 environment 까지 모두 관리 하는 폴더입니다. 개발환경 세팅하기 편하며 추후에 CI/CD를 세팅할때도 참고하기 편합니다.\np.s. docker-compose에서 nfs도 사용 할 수 있습니다! 만약 nfs를 사용하고 싶으시면(여기) 참고하시면 됩니다! src : 실제 실행되는 소스코드를 저장합니다. docker를 실행해 volume mount를 할때는 data, src 등 직관적인 폴더를 추가만 하면 되고 관리도 매우매우 편해졌습니다.  전체 Project Tree docker Tree docker-compose.yml 세팅 version: \u0026#39;3.1\u0026#39; services: Python1: #docker파일 이름 image: tensor_ai  #docker image 이름 deploy: #docker container 사양 설정 resources: limits: cpus: \u0026#39;1\u0026#39; build: #docker image build 방법  context: .  #build root 경로 이 위치를 dockerfile이 있는 폴더로 지정 한 다음 파일명만 써도 됨  dockerfile: python/Dockerfile  # Dockerfile 이름 지정 | Dockerfile이면 지정 안해도 되지만 혹시나 몰라서... volumes: - ../src:/src #컨테이너와 실제 서버 마운트 | 실제 서버 경로 : container 경로 environment: #컨테이너 안에서 사용할 환경변수  - NVIDIA_VISIBLE_DEVICES=1  #어떤 GPU를 사용할건지 입력 | 다중사용을 원하면 0,1 과 같이 \u0026#34;,\u0026#34;로 구분해서 넣으면 됨 - VideoPath=rtsp://admin:admin!@127.0.0.1 # 여기부터 아래는 실제 소스에서 사용할 env - CameraId=camera1  # Python에서 os.environ[\u0026#34;CameraId\u0026#34;] 로 사용  - DISPLAY=unix$DISPLAY  # openCV를 container 안에서 사용하려면 설정을 넣어 줘야함 - model=tensor_model command: python detectvideo.py  # 컨테이너가 올라갈때 입력할 명령어 stdin_open: true tty: true 위와 같이 docker-compose.yml 파일을 만들고 나서 docker compose up 명령어를 치면 docker container 안에서 GPU를 사용할 수 있습니다!\n1번 GPU에 잘 올라 가네요!\n혹시나 잘못된 정보가 있으면 피드백 해 주세요!\n감사합니다\n"
},
{
	"uri": "/tags/gpu/",
	"title": "GPU",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/postgres/",
	"title": "postgres",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/database/postgres-replication-setting/",
	"title": "postgres replication 하는방법",
	"tags": ["replication", "postgres"],
	"description": "",
	"content": "master 서버와 slave 서버에 각각 설정하는 방법이 다릅니다\nMASTER 설정   user 생성\n# psql을 Postgres 유저로 접속 후 유저 생성 sudo -u postgres psql CREATE ROLE replication WITH REPLICATION PASSWORD \u0026#39;password\u0026#39; LOGIN;   /etc/postgresql/9.5/main/postgresql.conf 파일 수정\nwal_level = hot_standby max_wal_senders = 2 max_replication_slots = 2   /etc/postgresql/9.5/main/hba.conf 파일 수정\n아래 문구 추가\nhost all all 192.168.0.138/24 trust host replication replication 192.168.0.138/24 md5 host all all ::1/128 trust   postgresql 재시작\n  STANDBY SERVER 세팅   /etc/postgresql/9.5/main/pg_hba.conf 파일 수정 아래문구 추가\nhost all all 192.168.0.0/24 trust   postgres 유저 추가\n# psql을 Postgres 유저로 접속 후 유저 생성 sudo -u postgres psql CREATE ROLE replication WITH REPLICATION PASSWORD \u0026#39;password\u0026#39; LOGIN;   master server backup 진행\n# 백업 진행하기 전 postgresql 종료 systemctl stop postgresql # 백업은 꼭 postgres 유저로 진행해야 됨 (중요) su postgres # /var/lib/postgresql/9.5/main 아래의 데이터는 데이터 베이스가 동작하는 main 디렉토리 # 하위 데이터가 없어야 백업이 정상적으로 실행됨 rm -rf /var/lib/postgresql/9.5/main/* pg_basebackup -h 192.168.0.123 -D /var/lib/postgresql/9.5/main/ -U replication -P -v -X stream   /var/lib/postgresql/9.5/main/recovery 파일 생성\nstandby_mode=\u0026#39;on\u0026#39; primary_conninfo=\u0026#39;host=192.168.0.123 port=5432 user=replication password=password\u0026#39; primary_slot_name=\u0026#39;repl_slot_01\u0026#39; trigger_file=\u0026#39;/var/lib/postgresql/9.5/main/failover_trigger\u0026#39;   postgresql 실행\nsystemctl start postgresql   replication 실행 확인   master 서버에서의 확인\nselect * from pg_stat_replication; 아래처럼 1 row 가 출력되면 1개의 replication이 돌고 있는 것   slave 에서의 확인\n/var/log/postgresql/postgresql-9.5-main.log 로그에서 아래와 같이 recovery 로그가 있으면 성공\n  master / slave 모두 확인\nps -ef | grep post 를 입력했을때 아래와 같이 recovering 이라는 프로세스가 돌고있으면 성공!\n  혹시 틀린부분 있으면 피드백 부탁드립니다!\n"
},
{
	"uri": "/tags/replication/",
	"title": "replication",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]